# After the Ceph Cluster is created, If you want to add new Ceph Node
# or add new OSD disk, you should do it one by one, NOT in a batch way.

- name: Update /etc/hosts on all targets
  hosts: all
  tags: ['always']
  roles:
    - util/zerostep
    - util/update_hosts

# run ceph-deploy on first node of ceph-mon
- name: Add OSD to ceph cluster
  hosts:
    - ceph-mon[0]
  roles:
    - role: predeploy/predeploy
      tags: ['always']

    - role: util/push_ssh_keys
      ssh_keys_targets: "{{ groups['ceph-all'] }}"

    - role: ceph/ceph-deploy-osd
      ceph_deploy_dir: "{{ osdm_ceph_deploy_dir }}"
      ceph_deploy_ceph_osd_disks: "{{ osdm_ceph_osd_disks }}"

# If you run this playbook multiple times to add more osds into
# the ceph cluster, each time you run it, you shoudl override
# osdm_ceph_osd_disks variable to contain those added disks.
